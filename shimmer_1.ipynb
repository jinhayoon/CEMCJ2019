{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinhayoon/CEMCJ2019/blob/master/shimmer_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZBrvOsDflpQx",
        "outputId": "61338c20-c515-4356-bb25-9343f380a2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-774fa91421e1>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Process all files in the specified folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mshimmer_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Save the processed data to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-774fa91421e1>\u001b[0m in \u001b[0;36mprocess_folder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Process all files in the specified folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jinhayoon/Desktop/TOCHI/physio/healthcareshim'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class ShimmerDataProcessor:\n",
        "    def __init__(self, folder_path, output_path):\n",
        "        self.folder_path = folder_path\n",
        "        self.output_path = output_path\n",
        "        self.ppt_data = []\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        #load CSV and set timestamp column as index\n",
        "        data = pd.read_csv(file_path)\n",
        "        data.set_index('Shimmer_D2B1_TimestampSync_FormattedUnix_CAL', inplace=True)\n",
        "        return data\n",
        "\n",
        "    def resample_data(self, data, target_frequency='1S'):\n",
        "        #resample data to target frequency (1-second frequency)\n",
        "        data = data.resample(target_frequency).mean() #calculates mean within each resampling interval\n",
        "        return data\n",
        "\n",
        "    def apply_filter(self, data, cutoff_frequency=0.05, filter_order=4):\n",
        "        # Apply a low-pass Butterworth filter to each column of the data\n",
        "        fs = 1.0 #sampling frequency\n",
        "        b, a = signal.butter(filter_order, cutoff_frequency / (0.5 * fs), btype='low', analog=False)\n",
        "        filtered_data = pd.DataFrame()\n",
        "        for column in data.columns:\n",
        "            filtered_data[column] = signal.filtfilt(b, a, data[column]) #apply filter to each column\n",
        "        return filtered_data\n",
        "\n",
        "    def standardize_data(self, data):\n",
        "        # Standardize (normally distributed) data using sklearn's StandardScaler\n",
        "        scaler = StandardScaler()\n",
        "        return pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
        "\n",
        "    def extract_participant_id(self, file_name):\n",
        "        # Extract participant ID from the file name (modify based on naming convention)\n",
        "        #return file_name.split('_')[0]\n",
        "        print(f\"Processing CSV file: {file_name}\")\n",
        "        start_index = self.index(\"Session\") + len(\"Session\")\n",
        "        end_index = self.index(\"_Shimmer\")\n",
        "        PID = file_name[start_index:end_index]\n",
        "        print(\"extracted PID\", PID)\n",
        "        return PID\n",
        "\n",
        "    def identify_event_times(self, data):\n",
        "        # Assuming data is already resampled to 1-second intervals\n",
        "        event_start_time_1 = data.index[0]  # Start of the data\n",
        "        event_end_time_1 = data.index[105]  # 1 minute and 45 seconds (105 seconds)\n",
        "\n",
        "        event_start_time_2 = data.index[106]  # Start of the second interval\n",
        "        event_end_time_2 = data.index[-1]  # End of the data\n",
        "\n",
        "        return (event_start_time_1, event_end_time_1), (event_start_time_2, event_end_time_2)\n",
        "\n",
        "\n",
        "    def process_file(self, file_path):\n",
        "        participant_id = self.extract_participant_id(os.path.basename(file_path))\n",
        "        data = self.load_data(file_path)\n",
        "        data = self.resample_data(data)\n",
        "        filtered_data = self.apply_filter(data)\n",
        "        standardized_data = self.standardize_data(filtered_data)\n",
        "\n",
        "        # Identify event start and end times dynamically\n",
        "        (event_start_time_1, event_end_time_1), (event_start_time_2, event_end_time_2) = self.identify_event_times(data)\n",
        "\n",
        "        # Extract data within the specified event time windows\n",
        "        event_data_1 = standardized_data.loc[event_start_time_1:event_end_time_1]\n",
        "        event_data_2 = standardized_data.loc[event_start_time_2:event_end_time_2]\n",
        "\n",
        "        # Calculate cumulative values for skin conductance, skin resistance, and heart rate for each event\n",
        "        cumulative_values_1 = {\n",
        "            'ParticipantID': participant_id,\n",
        "            'EventStartTime': event_start_time_1,\n",
        "            'EventEndTime': event_end_time_1,\n",
        "            'Conductance': event_data_1['GSR'].sum(),\n",
        "            'Resistance': event_data_1['GSR'].mean(),\n",
        "            'HeartRate': event_data_1['HR'].mean()\n",
        "        }\n",
        "\n",
        "        cumulative_values_2 = {\n",
        "            'ParticipantID': participant_id,\n",
        "            'EventStartTime': event_start_time_2,\n",
        "            'EventEndTime': event_end_time_2,\n",
        "            'Conductance': event_data_2['GSR'].sum(),\n",
        "            'Resistance': event_data_2['GSR'].mean(),\n",
        "            'HeartRate': event_data_2['HR'].mean()\n",
        "        }\n",
        "\n",
        "        self.participant_data.append(cumulative_values_1)\n",
        "        self.participant_data.append(cumulative_values_2)\n",
        "\n",
        "    def process_folder(self):\n",
        "        # Process all files in the specified folder\n",
        "        for file_name in os.listdir(self.folder_path):\n",
        "            if file_name.endswith('.csv'):\n",
        "                file_path = os.path.join(self.folder_path, file_name)\n",
        "                self.process_file(file_path)\n",
        "\n",
        "    def save_output(self):\n",
        "        # Save processed data to a CSV file\n",
        "        output_df = pd.DataFrame(self.participant_data)\n",
        "        output_df.to_csv(self.output_path, index=False)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_path = '/Users/jinhayoon/Desktop/TOCHI/physio/healthcareshim'\n",
        "\n",
        "    timestamps = ['00:00:00', '00:01:45']\n",
        "\n",
        "    original_headers = ['Shimmer_D2B1_TimestampSync_FormattedUnix_CAL',\n",
        "                        'Shimmer_4A81_GSR_Skin_Conductance_CAL',\n",
        "                        'Shimmer_4A81_GSR_Skin_Resistance_CAL',\n",
        "                        'Shimmer_4A81_PPG_A13_CAL']\n",
        "\n",
        "    new_headers = ['PID', 'BASELINE_CONDUCTANCE', 'BASELINE_RESISTANCE', 'BASELINE_HEARTRATE',\n",
        "                   'CON_CONDUCTANCE', 'CON_RESISTANCE', 'CON_HEARTRATE']\n",
        "\n",
        "    output_path = '/Users/jinhayoon/Desktop/TOCHI/physio/healthcare_output'\n",
        "\n",
        "    # Create an instance of ShimmerDataProcessor\n",
        "    shimmer_processor = ShimmerDataProcessor(input_path, output_path)\n",
        "\n",
        "    # Process all files in the specified folder\n",
        "    shimmer_processor.process_folder()\n",
        "\n",
        "    # Save the processed data to a CSV file\n",
        "    shimmer_processor.save_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fQYZK-dlpQ1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}